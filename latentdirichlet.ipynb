{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated sample text data with \"technology\" and \"sports\" themes\n",
    "documents = [\"Smartphones are an essential piece of technology in today's digital age.\", \"Professional athletes train rigorously to excel in their respective sports.\", \"Electric vehicles represent a significant advancement in automotive technology.\", \"Watching sports events live offers an exhilarating experience for fans.\", \"Virtual reality technology immerses users in simulated environments for gaming and entertainment.\", \"Sports equipment manufacturers continually innovate to improve performance and safety.\", \"Artificial intelligence is being integrated into various aspects of modern technology.\", \"Participating in sports promotes physical fitness and overall wellbeing.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modelling using lda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #to convert text to numerical\n",
    "from sklearn.decomposition import LatentDirichletAllocation \n",
    "#Our goal with this code is to classify the text in the documents into different topics. We can accomplish that using LatentDirichletAllocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
    "X = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LDA\n",
    "from pyparsing import alphanums\n",
    "\n",
    "\n",
    "lda = LatentDirichletAllocation(learning_decay=0.65, learning_offset= 10, n_components= 2) #Assuming there are 2 topics\n",
    "lda.fit(X)\n",
    "\n",
    "# Assign each document to the topic with the highest probability\n",
    "topic_assignments = lda.transform(X).argmax(axis=1)\n",
    "\n",
    "# Group documents by their assigned topics\n",
    "topic_documents = {'Sports': [], 'Technology': []}\n",
    "for i, topic_idx in enumerate(topic_assignments):\n",
    " topic = 'Technology' if topic_idx == 0 else 'Sports'\n",
    " topic_documents[topic].append(documents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sports:\n",
      "- Professional athletes train rigorously to excel in their respective sports.\n",
      "- Electric vehicles represent a significant advancement in automotive technology.\n",
      "- Watching sports events live offers an exhilarating experience for fans.\n",
      "- Virtual reality technology immerses users in simulated environments for gaming and entertainment.\n",
      "- Artificial intelligence is being integrated into various aspects of modern technology.\n",
      "\n",
      "Technology:\n",
      "- Smartphones are an essential piece of technology in today's digital age.\n",
      "- Sports equipment manufacturers continually innovate to improve performance and safety.\n",
      "- Participating in sports promotes physical fitness and overall wellbeing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print documents grouped by topics\n",
    "for topic, docs in topic_documents.items():\n",
    "  print(f\"{topic}:\")\n",
    "  for doc in docs:\n",
    "    print(\"-\", doc)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'learning_decay': 0.5, 'learning_offset': 10, 'n_components': 5}\n",
      "Top 10 words for topic #0:\n",
      "['intelligence', 'integrated', 'aspects', 'significant', 'represent', 'automotive', 'electric', 'vehicles', 'advancement', 'technology']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['sports', 'virtual', 'users', 'gaming', 'simulated', 'entertainment', 'environments', 'immerses', 'reality', 'technology']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['experience', 'exhilarating', 'performance', 'continually', 'equipment', 'manufacturers', 'innovate', 'safety', 'improve', 'sports']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['essential', 'age', 'rigorously', 'professional', 'train', 'excel', 'respective', 'athletes', 'technology', 'sports']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['essential', 'age', 'rigorously', 'professional', 'train', 'excel', 'respective', 'athletes', 'technology', 'sports']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "search_params = {\n",
    "    'n_components': [5, 10, 15],\n",
    "    'learning_decay': [0.5, 0.7, 0.9],  # equivalent to beta\n",
    "    'learning_offset': [10, 50, 100]    # equivalent to alpha\n",
    "}\n",
    "model = LatentDirichletAllocation(random_state=42)\n",
    "gridsearch = GridSearchCV(model, param_grid=search_params, cv=3)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "gridsearch.fit(X)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best Params:\", gridsearch.best_params_)\n",
    "\n",
    "# Train the best LDA model\n",
    "best_lda = gridsearch.best_estimator_\n",
    "\n",
    "# Display the topics from the best model\n",
    "for i, topic in enumerate(best_lda.components_):\n",
    "    print(f\"Top 10 words for topic #{i}:\")\n",
    "    print([vectorizer.get_feature_names_out()[index] for index in topic.argsort()[-10:]])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
